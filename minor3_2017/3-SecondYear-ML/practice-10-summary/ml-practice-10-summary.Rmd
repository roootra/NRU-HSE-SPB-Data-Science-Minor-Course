---
title: "ML practice 10: summary"
output: html_document
---

В конце прошлого модуля (лабораторная номер 6) мы с вами уже подводили промежуточные итоги, а так же рассматривали общую схему анализа данных. Сегодня мы хотим обсудить с вами метолодогию CRISP-DM (CRoss Industry Standard Process for Data Mining), которая описывает анализ данных как бизнес-процесс.

CRISP-DM разбивает процесс анализа данных на шесть основных этапов, о которых мы и поговорим.

![](https://upload.wikimedia.org/wikipedia/commons/b/b9/CRISP-DM_Process_Diagram.png)

###Понимание бизнеса (Business Understanding)

Первая фаза процесса направлена на определение целей проекта и требований со стороны бизнеса. Затем эти знания конвертируются в постановку задачи интеллектуального анализа данных и предварительный план достижения целей проекта.

* Определить бизнес цели
    + Бэкграунд проекта (Background)
    + Цели бизнеса (Business objectives)
    + Условия успешности бизнеса (Business success criteria)
* Оценить ситуацию
    + Анализ ресурсов (Inventory of resources)
    + Требования, предположения, ограничения (Requirements, assumptions and constraints)
    + Риски (Risks and contingencies)
    + Терминология (Terminology)
    + Оценка доходности (Costs and benefits)
* Определить цели анализа данных
    + Цели анализа данных (Data mining goals)
    + Критерий успеха анализа данных (Data mining success criteria)
* Составить план проекта
    + План проекта (Project plan)
    + Первоначальная оценка инструментов и методов (Initial assessment of tools and techniques)


Данный этап имеет не очень много общего с технической стороной анализа данных, но достаточно важен в реальном мире.

Попробуйте сформулировать Бизнес цели для задачи кредитного скоринга.
Попробуйте сформулировать Бизнес цели для задачи определения пола по транзакциям.



###Понимание данных (Data Understanding)

Вторая фаза начинается со сбора данных и ставит целью познакомиться с данными как можно ближе. Для этого необходимо выявить проблемы с качеством данных, такие как ошибки или пропуски, понять, что за данные имеются в наличии, попробовать отыскать интересные наборы данных или сформировать гипотезы о наличии скрытых закономерностей в данных.

* Собрать исходные данные
* Описать данные
* Исследовать данные
* Проверить качество данных




Что вы уже можете рассказать про данные Сбербанка?

Кого в ваших данных больше женщин или мужчин? А в реальном мире?

Как распределены положительные и отрицательные транзакции? 


Сегодня вы попробуете проанализировать данные о кредитном скоринге, а мы поможем вам парой вопросов.

Где мы будем брать данные для кредитного скоринга?

Мы будем работать с данными [http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)](http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)), но модифицированными для удобства чтения. 

Еще одно удобное описание этих данных можно найти тут [https://onlinecourses.science.psu.edu/stat857/node/222](https://onlinecourses.science.psu.edu/stat857/node/222)


```{r}
german_credit <- read.csv("~/shared/minor3_2017/3-SecondYear-ML/practice-10-summary/german_credit.csv")
```


Посмотрите распределение клиентов по возрасту. Что вы можете сказать?

```{r}
#Вставьте свой код сюда

```

А насколько корректно загрузились данные?
Не надо ли преобразовать что-то к факторам?

```{r}
#Вставьте свой код сюда

```

Посмотрите на мужчин и женщин, можете ли вы извлечь пол из данных?

```{r}
#Вставьте свой код сюда

```

Не стоит ли объединить какие-то столбцы?

Выберите какие-нибудь 4 столбца и, используя ggpairs, посмотрите на данные.

```{r}
#Вставьте свой код сюда

```



###Подготовка данных (Data Preparation)

Фаза подготовки данных ставит целью получить итоговый набор данных, которые будут использоваться при моделировании, из исходных разнородных и разноформатных данных. Задачи подготовки данных могут выполняться много раз без какого-либо наперед заданного порядка. Они включают в себя отбор таблиц, записей и атрибутов, а также конвертацию и очистку данных для моделирования.

* Отобрать данные
* Очистить данные
* Сделать производные данные
* Объединить данные
* Привести данные в нужный формат

В контексте Сбербанка надо ли делать что-то?

Нам повезло, все данные мы получили из одного источника и на не надо ничего объединять.
Нужно ли что-то чистить?

В целом препроцессиг можно сделать в таком виде как в этом примере: [https://onlinecourses.science.psu.edu/stat857/node/216](https://onlinecourses.science.psu.edu/stat857/node/216)



###Моделирование (Modeling)

В этой фазе к данным применяются разнообразные методики моделирования, строятся модели и их параметры настраиваются на оптимальные значения. Обычно для решения любой задачи анализа данных существует несколько различных подходов. Некоторые подходы накладывают особые требования на представление данных. Таким образом часто бывает нужен возврат на шаг назад к фазе подготовки данных.

* Выбрать методику моделирования
* Сделать тесты для модели
* Построить модель
* Оценить модель

Это основной и самый интереный этап анализа данных. Именно здесь мы делим данные на тестовую и обучающую выборку, которые будем использовать для оценки качества.

Разбейте данные на обучающую и тестовую выборку. Возьмите в тест 20%.

```{r}
#Вставьте свой код сюда

```

Попробуйте построить логистическую регрессию. И оцените ее качество.
```{r}
#Вставьте свой код сюда

```

Попробуйте использовать рекурсивный отбор фич и сравните на тесте с предыдущей моделью.
```{r eval = F}
library(caret)
# эта часть не меняется - переопределение функции для rfeControl
glmFuncs=lmFuncs 
glmFuncs$fit=function (x, y, first, last, ...) {
  tmp <- as.data.frame(x) 
  tmp$y <- y 
  glm(y ~ ., data = tmp, family=binomial(link='logit'))
}
#конец не изменяемой части
# использование: rfeControl(functions = glmFuncs, ...)
```

Постройте дерево решений (ctree).
```{r}
#Вставьте свой код сюда

```

Выберите лучшую модель на тесте.
```{r}
#Вставьте свой код сюда

```


###Оценка (Evaluation)

На этом этапе проекта уже построена модель и получены количественные оценки её качества. Перед тем, как внедрять эту модель, необходимо убедиться, что мы достигли всех поставленных бизнес-целей. Основной целью этапа является поиск важных бизнес-задач, которым не было уделено должного внимания.

Важно: на этом этапе мы оцениваем не качество модели (это было на предыдущем этапе), а оцениваем, решают ли полученные результаты поставленную бизнес задачу.

Например, если задачей была умеьшить потери, то можно оценить, будет ли новый прогноз уменьшать потери и увеличит ли доход. Может оказаться, что неиспользование модели может быть выгоднее чем использование.


* Оценить результаты
* Сделать ревью процесса
* Определить следующие шаги

###Развертывание (Deployment)

В зависимости от требований фаза развертывания может быть простой, например, составление финального отчета, или сложной, например, автоматизация процесса анализа данных для решения бизнес-задач. Обычно развертывание — это забота клиента. Однако, даже если аналитик не принимает участие в развертывании, важно дать понять клиенту, что ему нужно сделать для того, чтобы начать использовать полученные модели.

* Запланировать развертывание
* Запланировать поддержку и мониторинг развернутого решения
* Сделать финальный отчет
* Сделать ревью проекта


На примере задачи кредитного скоринга, внедрение -- это обучение менеджеров использованию вашей модели для вынесения вердикта.


## Итого

Мы обсудили основные этапы анализа данных, как бизнес-процесса. В идеальном варианте именно так должен будет быть построен ваш проект следующего семестра.

