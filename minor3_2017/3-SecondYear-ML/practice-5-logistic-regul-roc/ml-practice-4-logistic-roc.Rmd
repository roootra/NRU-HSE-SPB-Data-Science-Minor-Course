---
title: "ML practice 5: Logistic regression. ROC-curve, AUC"
output: html_document
---

Продолжаем изучать методы классификации. И сегодня мы говорим о регрессии для классификации. А точнее -- о логистической регрессии

```{r}
library(caret)
library(ggplot2)
```


### Данные

Датасет, с которым мы работаем сегодня -- результаты диагностики диабета. 


```{r}
library(mlbench)
data(PimaIndiansDiabetes2)
library(dplyr)
#Diabetes = na.omit(PimaIndiansDiabetes2)
Diabetes = PimaIndiansDiabetes2
```


## Регрессия для бинарных предсказаний

Разбиение на тестовую и обучающую

```{r message = F, warning=FALSE}
set.seed(100) #You shoud put here your own number
test.ind = createDataPartition(Diabetes$diabetes, p = 0.2, list = FALSE)
Diabetes.test = Diabetes[test.ind,]
Diabetes.main = Diabetes[-test.ind,]
```

diabetes -- это фактор (neg/pos). 

Давайте немного изменим датасет: 

* введем новую переменную `db` = 1, если есть диабет, 0, если нет;  
* удалим переменную diabetes (иначе предсказания однозначны)

```{r}
Diabetes.main2 = mutate(Diabetes.main, db = as.numeric(diabetes=="pos"))
Diabetes.main2 = dplyr::select(Diabetes.main2, -diabetes)
```

Построение линейной модели
```{r}
lm.model <- lm(db~., data = Diabetes.main2)
summary(lm.model)
```

Посмотрим на соответствие реальных и предсказанных значений

```{r}
ggplot() + geom_point(aes(x=Diabetes.main2$db, y = predict(lm.model, Diabetes.main2))) + 
  geom_hline(yintercept = c(0,1), color = "red") +
  xlab("Реальные значения")+
  ylab("Предсказанные значения")
```

Как делать выводы о наличии или отсутствии диабета? Т.е. если значения от 0 до 1 еще можно было попробовать обосновать как некую "вероятность", то что делать со значениями, попадающими сильно за эти пределы

Но аппарат регрессии все равно использовать хочется. Выход был найден следующий: давайте предсказывать не само значение, а вероятность попадания в класс = 1. Раз это вероятность, то она должна быть в промежутке от 0 до 1. Преобразуем немного наше значение с помощью сигмоидной функции -- какое бы значение мы ни использовали в Input, Output будет от 0 до 1. Формула для сигмоидной функции $f(x)=e^x/(e^x+1)$.

![](http://blog.hackerearth.com/wp-content/uploads/2017/01/SigmoidPlot1.png)

В контексте регрессии получаем (для любителей формул)

![](http://blog.hackerearth.com/wp-content/uploads/2017/01/equateimage-e1483685096494.png)

А отсюда получаем и интепретацию коэффициентов регрессии: увеличение значения на 1 приводит к увеличению шансов в $e^{коэффициент}$ раз.

## Построение модели

Теперь к тому, как получить логистическую регрессию в R (работает и с факторами!)

```{r}
log.model = glm(diabetes~., data = Diabetes.main, family = binomial(link = 'logit'))
summary(log.model)

log.model2 = glm(db~., data = Diabetes.main2, family = binomial(link = 'logit'))
summary(log.model2)
```

## Еще раз про метрики

![](https://images.nature.com/full/nature-assets/nmeth/journal/v13/n8/images_article/nmeth.3945-F1.jpg)

Посмотрим на предсказание. Напомню -- предсказываем вероятность. Как по этим значениям отнести к тому или иному классу?

```{r}
pred = predict(log.model, newdata = Diabetes.test, type = "response")
head(pred)
```

**Обратите внимание**: по умолчанию выдается не вероятность, а значение функции. Которая, правда, легко преобразуется в вероятность подстановкой в сигмоидную функцию

```{r}
predLink = predict(log.model, newdata = Diabetes.test)
head(predLink)
head(exp(predLink)/(exp(predLink)+1))
```

Значение классов можем определить, задав границу разделения
```{r}
pred0.5 <- ifelse(pred > 0.5,"pos","neg")
head(pred0.5)
caret::confusionMatrix(pred0.5, Diabetes.test$diabetes)
```

А если поменять границу? 
```{r}
pred0.7 <- ifelse(pred > 0.7,"pos","neg")
caret::confusionMatrix(pred0.7, Diabetes.test$diabetes)
```

Как выбрать? Более того, если у нас несколько подобных моделей, то как узнать, какая модель лучше?

## ROC & AUC

Метрики оценки качества в этом случае

* ROC-кривая (Receiver Operating Characteristic) -- график, показывающий соотношение между долей объектов от общего количества носителей признака, верно классифицированных как несущих признак, (true positive rate, TPR, sensitivity, чувствительность алгоритма классификации) и долей объектов от общего количества объектов, не несущих признака, ошибочно классифицированных как несущих признак (англ. false positive rate, FPR, 1-FPR = specificity, специфичность алгоритма классификации) при разных значениях границы, разделяющей классы
* AUC (Area Under ROC Curve) -- площадь под этой кривой

```{r}
library(pROC)
ROCfull = roc(response = Diabetes.test$diabetes, predictor = pred)
plot(ROCfull)
plot(ROCfull, legacy.axes=T)
pROC::auc(ROCfull)
```

Можно использовать не весь объект, а отдельно specificity и sensitivity и построить ROC с помощью, например, ggplot2

```{r}
ggplot() + geom_path(aes(y=ROCfull$sensitivities, x=1-ROCfull$specificities))+
  xlab("FPR") + ylab("TPR")
```

Построим еще одну модель

```{r}
log.modelSmall = glm(diabetes~age, data = Diabetes.main, family = binomial(link = 'logit'))
summary(log.modelSmall)
predSmall = predict(log.modelSmall, newdata = Diabetes.test, type = "response")

log.modelGlucose = glm(diabetes~glucose, data = Diabetes.main, family = binomial(link = 'logit'))
predGluck = predict(log.modelGlucose, newdata = Diabetes.test, type = "response")



ROCsmall = roc(response = Diabetes.test$diabetes, predictor = predSmall)
pROC::auc(ROCsmall)
ROCgluck = roc(response = Diabetes.test$diabetes, predictor = predSmall)
pROC::auc(ROCsmall)

ggplot() + geom_path(aes(y=ROCfull$sensitivities, x=1-ROCfull$specificities)) +
  geom_path(aes(y=ROCsmall$sensitivities, x=1-ROCsmall$specificities), color = "blue") +
  geom_path(aes(y=ROCgluck$sensitivities, x=1-ROCgluck$specificities), color = "green") +
  
  xlab("FPR") + ylab("TPR")
```

Какая модель лучше?

**Ваша  очередь:** 


Уже рассмотренные данные про продажи детских автомобильных кресел. Задача: предсказать уровень продаж. Т.к. задача классификации предполагает, что целевая переменная (в нашем случае -- продажи Sales), должна быть категориальной, то изменим немного наши данные -- разделим их на высокие и низкие.

```{r}
library(ISLR)
library(dplyr)
carseats <- ISLR::Carseats
carseats <- carseats %>% 
  mutate(High = ifelse(Sales <= 8, "No", "Yes")) %>% 
  dplyr::select(-Sales) 
carseats$High = as.factor(carseats$High)
```

